{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Skillfactory---Практический-Machine-Learning\" data-toc-modified-id=\"Skillfactory---Практический-Machine-Learning-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Skillfactory - Практический Machine Learning</a></div><div class=\"lev2 toc-item\"><a href=\"#19/02/2018---Аномалии,-работа-с-признаками,-пайплайны\" data-toc-modified-id=\"19/02/2018---Аномалии,-работа-с-признаками,-пайплайны-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>19/02/2018 - Аномалии, работа с признаками, пайплайны</a></div><div class=\"lev1 toc-item\"><a href=\"#(Де)мотивация\" data-toc-modified-id=\"(Де)мотивация-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>(Де)мотивация</a></div><div class=\"lev4 toc-item\"><a href=\"#Рассмотрим-кейс\" data-toc-modified-id=\"Рассмотрим-кейс-2001\"><span class=\"toc-item-num\">2.0.0.1&nbsp;&nbsp;</span>Рассмотрим кейс</a></div><div class=\"lev1 toc-item\"><a href=\"#(Anomaly-Detection)-Выявление-аномалий\" data-toc-modified-id=\"(Anomaly-Detection)-Выявление-аномалий-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>(Anomaly Detection) Выявление аномалий</a></div><div class=\"lev2 toc-item\"><a href=\"#Примеры-задач,-где-выявление-аномалий---сама-цель\" data-toc-modified-id=\"Примеры-задач,-где-выявление-аномалий---сама-цель-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Примеры задач, где выявление аномалий - сама цель</a></div><div class=\"lev2 toc-item\"><a href=\"#Moscow-Data-Science-Meetup-report\" data-toc-modified-id=\"Moscow-Data-Science-Meetup-report-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span><a href=\"https://youtu.be/o5QCVyI0dSA?t=1994\" target=\"_blank\">Moscow Data Science Meetup report</a></a></div><div class=\"lev2 toc-item\"><a href=\"#Влияние-аномалий-в-данных-на-модели\" data-toc-modified-id=\"Влияние-аномалий-в-данных-на-модели-33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Влияние аномалий в данных на модели</a></div><div class=\"lev2 toc-item\"><a href=\"#Подходы-к-решению\" data-toc-modified-id=\"Подходы-к-решению-34\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Подходы к решению</a></div><div class=\"lev3 toc-item\"><a href=\"#Ответы-алгоритмов\" data-toc-modified-id=\"Ответы-алгоритмов-341\"><span class=\"toc-item-num\">3.4.1&nbsp;&nbsp;</span>Ответы алгоритмов</a></div><div class=\"lev2 toc-item\"><a href=\"#Визуальный-анализ\" data-toc-modified-id=\"Визуальный-анализ-35\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Визуальный анализ</a></div><div class=\"lev2 toc-item\"><a href=\"#Методы,-основанные-на-плотности-и-расстоянии\" data-toc-modified-id=\"Методы,-основанные-на-плотности-и-расстоянии-36\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Методы, основанные на плотности и расстоянии</a></div><div class=\"lev3 toc-item\"><a href=\"#Local-Outlier-Factor\" data-toc-modified-id=\"Local-Outlier-Factor-361\"><span class=\"toc-item-num\">3.6.1&nbsp;&nbsp;</span>Local Outlier Factor</a></div><div class=\"lev2 toc-item\"><a href=\"#Методы-машинного-обучения\" data-toc-modified-id=\"Методы-машинного-обучения-37\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Методы машинного обучения</a></div><div class=\"lev3 toc-item\"><a href=\"#Изолирующий-лес\" data-toc-modified-id=\"Изолирующий-лес-371\"><span class=\"toc-item-num\">3.7.1&nbsp;&nbsp;</span>Изолирующий лес</a></div><div class=\"lev2 toc-item\"><a href=\"#Методы-основанные-на-кластеризации\" data-toc-modified-id=\"Методы-основанные-на-кластеризации-38\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>Методы основанные на кластеризации</a></div><div class=\"lev1 toc-item\"><a href=\"#Дисбаланс-классов\" data-toc-modified-id=\"Дисбаланс-классов-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Дисбаланс классов</a></div><div class=\"lev2 toc-item\"><a href=\"#Способы-балансировки-классов\" data-toc-modified-id=\"Способы-балансировки-классов-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Способы балансировки классов</a></div><div class=\"lev3 toc-item\"><a href=\"#Сэмплирование\" data-toc-modified-id=\"Сэмплирование-411\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Сэмплирование</a></div><div class=\"lev2 toc-item\"><a href=\"#Under-sampling\" data-toc-modified-id=\"Under-sampling-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Under-sampling</a></div><div class=\"lev2 toc-item\"><a href=\"#Over-sampling\" data-toc-modified-id=\"Over-sampling-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Over sampling</a></div><div class=\"lev2 toc-item\"><a href=\"#SMOTE\" data-toc-modified-id=\"SMOTE-44\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>SMOTE</a></div><div class=\"lev3 toc-item\"><a href=\"#Synthetic-Minority-Over-sampling-Technique\" data-toc-modified-id=\"Synthetic-Minority-Over-sampling-Technique-441\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>Synthetic Minority Over-sampling Technique</a></div><div class=\"lev2 toc-item\"><a href=\"#Ансамблевые-методы\" data-toc-modified-id=\"Ансамблевые-методы-45\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Ансамблевые методы</a></div><div class=\"lev3 toc-item\"><a href=\"#Easy-Ensemble\" data-toc-modified-id=\"Easy-Ensemble-451\"><span class=\"toc-item-num\">4.5.1&nbsp;&nbsp;</span>Easy Ensemble</a></div><div class=\"lev2 toc-item\"><a href=\"#Попробуем-сами\" data-toc-modified-id=\"Попробуем-сами-46\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Попробуем сами</a></div><div class=\"lev1 toc-item\"><a href=\"#Пропущенные-значения\" data-toc-modified-id=\"Пропущенные-значения-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Пропущенные значения</a></div><div class=\"lev2 toc-item\"><a href=\"#Наиболее-распространенные-способы-работы-с-пропусками\" data-toc-modified-id=\"Наиболее-распространенные-способы-работы-с-пропусками-51\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Наиболее распространенные способы работы с пропусками</a></div><div class=\"lev1 toc-item\"><a href=\"#Работа-с-признаками\" data-toc-modified-id=\"Работа-с-признаками-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Работа с признаками</a></div><div class=\"lev2 toc-item\"><a href=\"#Категориальные-признаки\" data-toc-modified-id=\"Категориальные-признаки-61\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Категориальные признаки</a></div><div class=\"lev2 toc-item\"><a href=\"#Бинирование-признаков\" data-toc-modified-id=\"Бинирование-признаков-62\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Бинирование признаков</a></div><div class=\"lev2 toc-item\"><a href=\"#Feature-Selection-(для-Supervised-Models)\" data-toc-modified-id=\"Feature-Selection-(для-Supervised-Models)-63\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Feature Selection (для Supervised Models)</a></div><div class=\"lev4 toc-item\"><a href=\"#Filter-method---Mutual-Information\" data-toc-modified-id=\"Filter-method---Mutual-Information-6301\"><span class=\"toc-item-num\">6.3.0.1&nbsp;&nbsp;</span>Filter method - Mutual Information</a></div><div class=\"lev4 toc-item\"><a href=\"#Filter-method---Information-Value,-Weight-Of-Evidence\" data-toc-modified-id=\"Filter-method---Information-Value,-Weight-Of-Evidence-6302\"><span class=\"toc-item-num\">6.3.0.2&nbsp;&nbsp;</span>Filter method - Information Value, Weight Of Evidence</a></div><div class=\"lev4 toc-item\"><a href=\"#Wrapper-methods\" data-toc-modified-id=\"Wrapper-methods-6303\"><span class=\"toc-item-num\">6.3.0.3&nbsp;&nbsp;</span>Wrapper methods</a></div><div class=\"lev4 toc-item\"><a href=\"#Embedded-methods\" data-toc-modified-id=\"Embedded-methods-6304\"><span class=\"toc-item-num\">6.3.0.4&nbsp;&nbsp;</span>Embedded methods</a></div><div class=\"lev2 toc-item\"><a href=\"#CountVectorizer-и-TF-IDF\" data-toc-modified-id=\"CountVectorizer-и-TF-IDF-64\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>CountVectorizer и TF-IDF</a></div><div class=\"lev3 toc-item\"><a href=\"#Анализ-тональности\" data-toc-modified-id=\"Анализ-тональности-641\"><span class=\"toc-item-num\">6.4.1&nbsp;&nbsp;</span>Анализ тональности</a></div><div class=\"lev4 toc-item\"><a href=\"#Загрузите-текстовые-данные-отсюда.-Архив-должен-содержать-3-файла-с-положительными-и-отрицательными-отзывами-с-ресурсов\" data-toc-modified-id=\"Загрузите-текстовые-данные-отсюда.-Архив-должен-содержать-3-файла-с-положительными-и-отрицательными-отзывами-с-ресурсов-6411\"><span class=\"toc-item-num\">6.4.1.1&nbsp;&nbsp;</span>Загрузите текстовые данные <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00331/\" target=\"_blank\">отсюда</a>. Архив должен содержать 3 файла с положительными и отрицательными отзывами с ресурсов</a></div><div class=\"lev4 toc-item\"><a href=\"#Задача\" data-toc-modified-id=\"Задача-6412\"><span class=\"toc-item-num\">6.4.1.2&nbsp;&nbsp;</span>Задача</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skillfactory - Практический Machine Learning\n",
    "## 19/02/2018 - Аномалии, работа с признаками, пайплайны\n",
    "\n",
    "<center> Шестаков Андрей </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ipywidgets import interact, IntSlider, FloatSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Де)мотивация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дата саенс - это про только fit-predict, но и.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='img/time.jpg' width=900><center\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И большую часть времени занимает именно работа с данными:\n",
    "* составление набора данных для обучения (!)\n",
    "* трансформация признаков к подходящему формату\n",
    "* отчистка от выбросов\n",
    "* анализ пропущенных значений\n",
    "* составление новых признаков\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='img/time2.png' width=500><center\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему это так важно?\n",
    "\n",
    "Никто не отменял правило: ** garbage in - garbage out **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Рассмотрим кейс\n",
    "\n",
    "Некий банк выдает кредит.\n",
    "\n",
    "* Приходит заявитель, подает анкету\n",
    "* Анкета проверяется\n",
    "* Для каждого заявителя собираются признаки (по анкете и из кредитного бюро)\n",
    "* Если банка все устравивает, то заявитель получается кредит и запоминается результат (вернул ли кредут вовремя)\n",
    "\n",
    "Прошло время, банк решил сделать модель, основываясь на накопленных данных, чтобы выдавать кредиты быстрее и добросовестным людям.\n",
    "\n",
    "* Данные - признаки заявителей\n",
    "* Таргет - вернет или нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построили модель. Выдаем кредит только людям с достаточно большой вероятностью возврата. Без первичной фильтрации, как было раньше.\n",
    "\n",
    "При анализе качества заметили, что число невозвратов осталось таким же (или увеличилось). Почему так могло произойти?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Think about it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Anomaly Detection) Выявление аномалий\n",
    "\n",
    "aka\n",
    "* Outlier detection (выявление выбросов)\n",
    "* Novelty detection (выявление новизны в данных)\n",
    "* Noise detection (выявление шумов в данных)\n",
    "* Deviation detection (выявление отклонений в данных)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Аномалии** - наблюдения, которые отличаются от большинства остальных объектов и не соотносятся с ожидаемой структурой данных\n",
    "\n",
    "Количество аномалий в данных (если они есть) *ничтожно* мало по сравнению с количеством нормальных объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры задач, где выявление аномалий - сама цель\n",
    "* Мошеннические действия (fraud detection)\n",
    "    * несогласованные операции по кредитным картам, \n",
    "    * взлом аккаунта\n",
    "* Проверка валидности (согласованности) записей базе данных\n",
    "    * ошибки (подтосовки) в сборе данных\n",
    "* Мониторинг стабильности систем\n",
    "    * преждевременное предупреждение сбоя на производстве"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Moscow Data Science Meetup report](https://youtu.be/o5QCVyI0dSA?t=1994)\n",
    "<center><img src='img/kasper.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Влияние аномалий в данных на модели\n",
    "\n",
    "* Аномалии могут привести как к переобучению, так и к недообучению\n",
    "* Пример недообучения мы видели в лекции по регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подходы к решению\n",
    "* **Обучение без учителя** \n",
    "    * Меток нет\n",
    "    * Используется некоторое представление о том, что такое аномалия\n",
    "* **Частичное обучение** \n",
    "    * Известны только метки \"нормальных\" данных\n",
    "* **Обучение с учителем**\n",
    "    * Известны метки \"нормальных\" и аномальных данных\n",
    "\n",
    "\n",
    "### Ответы алгоритмов\n",
    "* Скор аномальности\n",
    "* Метка аномальности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуальный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><img src='img/boyfriend.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные: [Задача предсказания отклика клиентов ОТП Банка](http://www.machinelearning.ru/wiki/index.php?title=%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BF%D1%80%D0%B5%D0%B4%D1%81%D0%BA%D0%B0%D0%B7%D0%B0%D0%BD%D0%B8%D1%8F_%D0%BE%D1%82%D0%BA%D0%BB%D0%B8%D0%BA%D0%B0_%D0%BA%D0%BB%D0%B8%D0%B5%D0%BD%D1%82%D0%BE%D0%B2_%D0%9E%D0%A2%D0%9F_%D0%91%D0%B0%D0%BD%D0%BA%D0%B0_%28%D0%BA%D0%BE%D0%BD%D0%BA%D1%83%D1%80%D1%81%29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_otp():\n",
    "    features = pd.read_csv('data/descr.txt', sep='\\t', encoding='cp1251', names=['feature', 'descr'])\n",
    "    \n",
    "    features = features.iloc[3:]\n",
    "    feature_names = features.iloc[:, 0].values\n",
    "    \n",
    "    df_data_x = pd.read_csv('data/data_x.csv', sep=';', header=None, names=feature_names)\n",
    "    df_data_x.loc[:, 'PREVIOUS_CARD_NUM_UTILIZED'] = df_data_x.PREVIOUS_CARD_NUM_UTILIZED.fillna(0)\n",
    "    \n",
    "    features.loc[:, 'uniq_vals'] = df_data_x.apply(lambda c: c.nunique(), axis=0).values\n",
    "    \n",
    "    features = features.reset_index(drop=True)\n",
    "    \n",
    "    df_data_y = pd.read_csv('data/data_y.csv', sep=';', names=['active'])\n",
    "    \n",
    "    idx = np.where(df_data_x.dtypes == 'object')[0]\n",
    "\n",
    "    for i in idx:\n",
    "        df_data_x.iloc[:, i] = df_data_x.iloc[:, i].str.replace(',', '.').astype('float')\n",
    "        \n",
    "    df_data = df_data_x.join(df_data_y)\n",
    "    \n",
    "    return df_data, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Методы, основанные на плотности и расстоянии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Предположение 1**: Аномальные объекты расположены далеко от остальных объектов\n",
    "* Считаем расстояние до k-го ближайшего соседа\n",
    "\n",
    "**Предположение 2**: Аномальные объекты расположены в разреженых областях\n",
    "* Считаем \"плотность\" вокруг каждого объекта как обратное от среднего расстояние до $k$ ближайших соседей:\n",
    "$$ density_k(a) = 1 \\Biggm/ \\left(\\frac{\\sum\\limits_{b\\in N_k(a)} d(a, b)}{|N_k(a)|} \\right)$$\n",
    "    * Когда это не взлетит?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['AGE', 'GENDER', 'FAMILY_INCOME', 'CHILD_TOTAL', 'PERSONAL_INCOME', 'DEPENDANTS',\n",
    "        'REG_FACT_FL', u'FACT_POST_FL', u'REG_POST_FL', u'REG_FACT_POST_FL',\n",
    "        u'REG_FACT_POST_TP_FL', u'FL_PRESENCE_FL',\n",
    "        u'OWN_AUTO', u'AUTO_RUS_FL', u'HS_PRESENCE_FL', u'COT_PRESENCE_FL',\n",
    "        u'GAR_PRESENCE_FL', u'LAND_PRESENCE_FL',\n",
    "        u'CREDIT', 'FST_PAYMENT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.loc[:, cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_ = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "model = NearestNeighbors(n_neighbors=k)\n",
    "model.fit(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Outlier Factor\n",
    "* Идея: давайте сравнивать плотность объектов с плотностями их $k$ ближайших соседей\n",
    "* Чтобы повысить стабильность в условии разной плотности будет считать reachability-distance:\n",
    "$$ \\text{reachability-distance}_k(a, b) = \\max\\left(k-\\text{distance}(a), d(a,b) \\right)$$\n",
    "<center><img src='https://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/Reachability-distance.svg/250px-Reachability-distance.svg.png' width=300></center>\n",
    "* Считаем плотность - local reachability density:\n",
    "$$ lrd(a) = 1 \\Biggm/ \\left(\\frac{\\sum\\limits_{b\\in N_k(a)} \\text{reachability-distance}_k(a, b)}{|N_k(a)|} \\right)$$\n",
    "* Сравнивам с соседями:\n",
    "$$LOF_k(a) = \\frac{1}{|N_k(a)|}\\sum\\limits_{b\\in N_k(a)}\\frac{lrd(b)}{lrd(a)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['AGE', 'GENDER', 'FAMILY_INCOME', 'CHILD_TOTAL', 'PERSONAL_INCOME', 'DEPENDANTS',\n",
    "        'REG_FACT_FL', u'FACT_POST_FL', u'REG_POST_FL', u'REG_FACT_POST_FL',\n",
    "        u'REG_FACT_POST_TP_FL', u'FL_PRESENCE_FL',\n",
    "        u'OWN_AUTO', u'AUTO_RUS_FL', u'HS_PRESENCE_FL', u'COT_PRESENCE_FL',\n",
    "        u'GAR_PRESENCE_FL', u'LAND_PRESENCE_FL',\n",
    "        u'CREDIT', 'FST_PAYMENT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.loc[:, cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_ = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Изолирующий лес\n",
    "**Предположение**: Аномальные объекты быстрее изолируются от остальных наблюдений в данных\n",
    "<center><img src='img/isofor.png' width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Каждое дерево в изолирующем лесу строится по следующим правилам:\n",
    "* Дерево строится на случайной подвыборке заданного размера\n",
    "* В каждой вершине выбирается случайный признак и случайный порог\n",
    "* Дерево строится до максимальной глубины\n",
    "\n",
    "Авторы рекомендуют использовать 256 объектов для обучения каждого дерева и 100 деревьев в лесу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Мера аномальности - средняя длина пути по деревьям лесу*\n",
    "<center><img src='img/isofor2.png' width=400></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы основанные на кластеризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Предположение 1**: \"Нормальные\" наблюдения принадлежат некоторому кластеру, а аномальные - нет\n",
    "* DBSCAN\n",
    "* OPTICS\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Предположение 2**: \"Нормальные\" наблюдения расплолжены близко к центрам кластеров, а аномалии - далеко\n",
    "* Посчитать (относительное) расстояние до центройдов\n",
    "$$ d_{rel}(x_i, \\mu_{C_j}) = \\frac{d(x_i, \\mu_{C_j})}{median([d(x, \\mu_{C_j}) \\ \\forall x \\in C_j])}, \\quad x_i \\in C_j$$\n",
    "* После кластеризации итеративно удалять объекты, которые сильнее всего портят критерий алгоритма\n",
    "* Удалять кластеры, расположенные далеко (?) от остальных кластеров\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее про кластеризацию расскажем на следующих занятиях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дисбаланс классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике, при решении задачи классификации, классы могут быть сильно дисбалансированны.\n",
    "\n",
    "Так как, обычно, модели считают объекты равноценными, то представителям минорного класса может уделяться меньшее внимание (просто потому что их мало)\n",
    "\n",
    "Нужно как-то сбалансировать задачу!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Способы балансировки классов\n",
    "* Взвешивание функции потерь\n",
    "$$ \\tilde{L}(X, \\theta) = \\sum_iw_iL(x_i, \\theta) $$\n",
    "Обычно $w_i$ обратно пропорциональны частоте соответствующего класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from imblearn.datasets import make_imbalance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def demo_weight(class_weight=None, ratio=0.5):\n",
    "\n",
    "    X_, y_ = make_moons(n_samples=500, shuffle=True, noise=0.3, random_state=0)\n",
    "    X, y = make_imbalance(X_, y_, ratio, random_state=0)\n",
    "\n",
    "    model = LogisticRegression(class_weight=class_weight).fit(X, y)\n",
    "    x0, x1 = np.meshgrid(np.linspace(-1, 2.5, 100),\n",
    "                         np.linspace(-2, 2, 100))\n",
    "    xx0, xx1 = x0.ravel(), x1.ravel()\n",
    "\n",
    "    X_grid = np.c_[xx0, xx1]\n",
    "\n",
    "    y_hat = model.decision_function(X_grid)\n",
    "    y_hat = y_hat.reshape(x0.shape)\n",
    "\n",
    "    plt.contour(x0, x1, y_hat, levels=[0])\n",
    "    plt.scatter(X[:,0], \n",
    "                X[:, 1], \n",
    "                c=y, cmap=plt.cm.flag_r)\n",
    "    plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "interact(demo_weight, class_weight=['balanced', None], ratio=FloatSlider(min=0.05, max=0.5, step=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Сэмплирование\n",
    "* Under-sampling\n",
    "* Over-sampling\n",
    "* Ensemble methods\n",
    "\n",
    "See  [imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Under-sampling\n",
    "Убираем представителей доминирующего класса\n",
    "* Случайным образом\n",
    "* Оставить эталонные объекты (ClusterCentroids)\n",
    "* Оставить объекты, наиболее похожие на представителей минорного класса (NearMiss)\n",
    "* Удалить объекты, в окрестности которых есть (много) представителей минорного класса (Condenced NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler, EditedNearestNeighbours, ClusterCentroids, CondensedNearestNeighbour\n",
    "\n",
    "def demo_under(ratio=0.5, sampler=None):\n",
    "\n",
    "    X_, y_ = make_moons(n_samples=500, shuffle=True, noise=0.3, random_state=0)\n",
    "    X, y = make_imbalance(X_, y_, ratio, random_state=0)\n",
    "    \n",
    "    sampler_model = \\\n",
    "              {'rand': RandomUnderSampler(random_state=0),\n",
    "               'cluster': ClusterCentroids(random_state=0),\n",
    "               'editnn': EditedNearestNeighbours(random_state=0),\n",
    "               'condnn': CondensedNearestNeighbour(random_state=0),\n",
    "               'nearmiss': NearMiss(random_state=0, version=1)}.get(sampler)\n",
    "    \n",
    "    if sampler:\n",
    "        X, y = sampler_model.fit_sample(X, y)\n",
    "\n",
    "    model = LogisticRegression(class_weight=None).fit(X, y)\n",
    "    x0, x1 = np.meshgrid(np.linspace(-1, 2.5, 100),\n",
    "                         np.linspace(-2, 2, 100))\n",
    "    xx0, xx1 = x0.ravel(), x1.ravel()\n",
    "\n",
    "    X_grid = np.c_[xx0, xx1]\n",
    "\n",
    "    y_hat = model.decision_function(X_grid)\n",
    "    y_hat = y_hat.reshape(x0.shape)\n",
    "\n",
    "    plt.contour(x0, x1, y_hat, levels=[0])\n",
    "    plt.scatter(X[:,0], \n",
    "                X[:, 1], \n",
    "                c=y, cmap=plt.cm.flag_r)\n",
    "    plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "interact(demo_under, ratio=FloatSlider(min=0.05, max=0.5, step=0.05), sampler=[None, 'rand', 'cluster', 'editnn', 'condnn', 'nearmiss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Over sampling\n",
    "Генерируем представителей минорного класса\n",
    "* Случайным образом из существующих\n",
    "* Синтетически, на основе существующих\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SMOTE\n",
    "### Synthetic Minority Over-sampling Technique\n",
    "* Для каждого представителя минорного класса найте $k$ ближайших соседей\n",
    "* Выбрать одного из соседей\n",
    "* Сгенерировать новый объект, расположеный между ними\n",
    "\n",
    "<center><img src='img/smote.png' width=400></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "def demo_over(ratio=0.5, sampler=None):\n",
    "\n",
    "    X_, y_ = make_moons(n_samples=500, shuffle=True, noise=0.3, random_state=0)\n",
    "    X, y = make_imbalance(X_, y_, ratio, random_state=0)\n",
    "    \n",
    "    sampler_model = \\\n",
    "              {'rand': RandomOverSampler(random_state=0),\n",
    "               'smote': SMOTE(),\n",
    "               }.get(sampler)\n",
    "    \n",
    "    if sampler:\n",
    "        X, y = sampler_model.fit_sample(X, y)\n",
    "\n",
    "    model = LogisticRegression(class_weight=None).fit(X, y)\n",
    "    x0, x1 = np.meshgrid(np.linspace(-1, 2.5, 100),\n",
    "                         np.linspace(-2, 2, 100))\n",
    "    xx0, xx1 = x0.ravel(), x1.ravel()\n",
    "\n",
    "    X_grid = np.c_[xx0, xx1]\n",
    "\n",
    "    y_hat = model.decision_function(X_grid)\n",
    "    y_hat = y_hat.reshape(x0.shape)\n",
    "\n",
    "    plt.contour(x0, x1, y_hat, levels=[0])\n",
    "    plt.scatter(X[:,0], \n",
    "                X[:, 1], \n",
    "                c=y, cmap=plt.cm.flag_r)\n",
    "    plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "interact(demo_over, ratio=FloatSlider(min=0.05, max=0.5, step=0.05), sampler=[None, 'rand', 'smote'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ансамблевые методы\n",
    "### Easy Ensemble\n",
    "\n",
    "* Строим несколько моделей на случайно сбалансированных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуем сами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as Pipeline_imb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pr_auc(estimator, X, y):\n",
    "    y_hat = estimator.predict_proba(X)[:, 1]\n",
    "    pr, rec, _ = precision_recall_curve(y, y_hat)\n",
    "    return auc(rec, pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data, features = load_otp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features[(features.uniq_vals>2) & (features.uniq_vals<100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_data.iloc[:, :-1].values\n",
    "y = df_data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline1 = Pipeline([\n",
    "    ('imputer', Imputer(strategy='median')),\n",
    "    ('scaller', StandardScaler()),\n",
    "    ('clf', LogisticRegression(random_state=123))\n",
    "])\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "    ('imputer', Imputer(strategy='median')),\n",
    "    ('scaller', StandardScaler()),\n",
    "    ('clf', LogisticRegression(class_weight='balanced', random_state=123))\n",
    "])\n",
    "\n",
    "pipeline3 = Pipeline_imb([\n",
    "    ('imputer', Imputer(strategy='median')),\n",
    "    ('scaller', StandardScaler()),\n",
    "    ('balancer', SMOTE()),\n",
    "    ('clf', LogisticRegression(random_state=123))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=123, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(pipeline1, X, y, scoring=pr_auc, cv=cv).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(pipeline2, X, y, scoring=pr_auc, cv=cv).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(pipeline3, X, y, scoring=pr_auc, cv=cv).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://i0.kym-cdn.com/entries/icons/original/000/024/153/soundsgood.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* На самом деле иногда работает =)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пропущенные значения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные - [Sberbank Russian Housing Market](https://www.kaggle.com/c/sberbank-russian-housing-market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat data/data_dictionary_sber.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip data/train_sber.csv.zip -y\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().mean().T.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df, sort='ascending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msno.matrix(df.iloc[:, :10], sort='ascending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.dendrogram(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Наиболее распространенные способы работы с пропусками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Замена средним (медианой, модой) по признаку\n",
    "* К-ближайших соседей\n",
    "* Модельный подход\n",
    "\n",
    "\n",
    "* Некоторые алгоритмы нормально относятся к пропущенным значениям\n",
    "    * Алгоритмы, основанные на деревьях\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ZeroImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        idx = np.isnan(X)\n",
    "        X[idx] = 0.0\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Много редких категории\n",
    "* One-hot encoding\n",
    "* Кодирование через другие переменные или данные\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бинирование признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот так (примерно) выглядит скор-карта на выдачу кредита"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://www.mathworks.com/help/finance/credit_score_card_overview.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый \"признак\" разбит на бины (bins) - значимые интервалы. Если значение признака попадает в интервал, то к скору заемщика прибавляется сооветвтвующая величина."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Как бы вы реализовали биннинг?\n",
    "* Библиотечка на R - [smbinning](http://blog.revolutionanalytics.com/2015/03/r-package-smbinning-optimal-binning-for-scoring-modeling.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection (для Supervised Models)\n",
    "Методы деляться на следующие группы:\n",
    "* Filter methods \n",
    "    * Признаки рассматриваются независимо друг от друга\n",
    "    * Изучается индивидуальный \"вклад\" призника в предсказываемую переменную\n",
    "    * Быстрое вычисление\n",
    "    * *Пример?*\n",
    "* Wrapper methods\n",
    "    * Идет отбор группы признаков\n",
    "    * Может быть оооочень медленным, но качество, обычно, лучше чем у Filter Methods\n",
    "    * Примеры: Stepwise feature selection for regression, [Boruta Algorithm](https://www.google.ru/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&ved=0ahUKEwif5biy-fTWAhXkYJoKHbdxCLAQFgg2MAE&url=https%3A%2F%2Fwww.jstatsoft.org%2Farticle%2Fview%2Fv036i11%2Fv36i11.pdf&usg=AOvVaw3tyiHN0BCe2fkkAA6xEVDE)\n",
    "* Embedded methods\n",
    "    * Отбор признаков \"зашит\" в модель\n",
    "\n",
    "#### Filter method - Mutual Information\n",
    "Пусть $X$ - категориальный признак, $Y$ - целевой признак (метка класса)\n",
    "$$MI(Y, X) = \\sum_{x,y} p(x,y) \\ln\\left[\\frac{p(x,y)}{p(x)p(y)}\\right]$$\n",
    "Сколько информации $x$ сообщает об $y$.\n",
    "\n",
    "#### Filter method - Information Value, Weight Of Evidence\n",
    "$$IV(Y,X) = \\sum_{x} \\left(p(y=1|x) - p(y=0|x)\\right)\\ln\\frac{p(y=1|x)}{p(y=0|x)} $$\n",
    "\n",
    "<img src='img/iv-sample.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrapper methods\n",
    "Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_data, features = load_otp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_data.iloc[:, :-1].values\n",
    "y = df_data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(5, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('imputer', Imputer(strategy='median')),\n",
    "    ('scaller', StandardScaler()),\n",
    "    ('clf', RFECV(LogisticRegression(class_weight='balanced'), \n",
    "                  verbose=2, cv=cv, scoring=pr_auc, n_jobs=1))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedded methods\n",
    "* Feature importance у деревьев решений\n",
    "* L1 регуляризация у линейной и логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer и TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ тональности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузите текстовые данные [отсюда](https://archive.ics.uci.edu/ml/machine-learning-databases/00331/). Архив должен содержать 3 файла с положительными и отрицательными отзывами с ресурсов\n",
    "* imdb.com\n",
    "* amazon.com\n",
    "* yelp.com\n",
    "\n",
    "Формат файла следующий:\n",
    "<отзыв>\\t<метка>\\n\n",
    "\n",
    "\n",
    "#### Задача\n",
    "1. Загрузите тексты и метки классов в разные переменные\n",
    "2. Выберите меру качества классификации\n",
    "3. Обучите логистическую (без подбора гиперпараметров). Тексты представляются в виде мешка слов\n",
    "4. Выведите наиболее значимые слова из текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/...txt', sep='\\t', \n",
    "                 header=None, \n",
    "                 names=['text', 'label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "347px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "222px",
    "left": "0px",
    "right": "1247.33px",
    "top": "108px",
    "width": "182px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "toc_position": {
   "height": "40px",
   "left": "816px",
   "right": "38.6667px",
   "top": "0px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
